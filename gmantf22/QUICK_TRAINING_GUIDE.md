# GMAN å¿«é€Ÿè®­ç»ƒæŒ‡å—

## 3 é˜¶æ®µæ¸è¿›å¼è®­ç»ƒæ–¹æ¡ˆ

### é—®é¢˜åˆ†æ
- åŸå§‹é…ç½®ï¼šL=5, K=8, d=8 â†’ 320ç»´ç‰¹å¾ï¼Œè®¡ç®—é‡å·¨å¤§
- batch_size=12 å¤ªå°ï¼ŒGPU åˆ©ç”¨ç‡ä½
- decay_epoch=5 å¯¼è‡´å­¦ä¹ ç‡è¡°å‡è¿‡å¿«

### é˜¶æ®µ 1ï¸âƒ£ï¼šå¿«é€ŸéªŒè¯ (5-15 åˆ†é’Ÿ)
**ç›®æ ‡**ï¼šå¿«é€Ÿå¾—åˆ°ä¸€ä¸ªèƒ½æ”¶æ•›çš„æ¨¡å‹ï¼ŒéªŒè¯ç®¡é“æ˜¯å¦å·¥ä½œ

```bash
# è¿è¡Œå¿«é€Ÿè®­ç»ƒ
python gmantf22/train_quick.py

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯æŸ¥çœ‹ TensorBoard
tensorboard --logdir=logs/fit_quick
```

**å¿«é€Ÿæ¨¡å¼é…ç½®**ï¼š
- L=2 (åŸ 5)
- K=4 (åŸ 8) 
- d=4 (åŸ 8)
- batch_size=32 (åŸ 12)
- max_epoch=50
- learning_rate=0.002 (æ›´æ¿€è¿›)
- enable_xla=False (å¿«é€Ÿç¼–è¯‘)

**é¢„æœŸç»“æœ**ï¼š
- 5-10 epoch çœ‹åˆ°æ˜æ˜¾ loss ä¸‹é™
- 20 epoch è¾¾åˆ°å¯ç”¨çš„ç²¾åº¦
- å¿«é€ŸéªŒè¯æ¨¡å‹æ²¡æœ‰ bug

---

### é˜¶æ®µ 2ï¸âƒ£ï¼šä¸­ç­‰è®­ç»ƒ (30-60 åˆ†é’Ÿ)
**ç›®æ ‡**ï¼šä½¿ç”¨æ›´å®Œæ•´çš„æ¨¡å‹ï¼Œä½†ä¸æ˜¯å®Œæ•´é…ç½®

åˆ›å»º `config_medium.py`ï¼š
```python
class GMANConfigMedium(BaseModel):
    L: int = Field(3, description="number of STAtt Blocks")
    K: int = Field(6, description="number of attention heads")
    d: int = Field(6, description="dims of each head attention outputs")
    batch_size: int = Field(24, description="batch size")
    max_epoch: int = Field(80, description="epoch to run")
    learning_rate: float = Field(0.0015, description="initial learning rate")
    decay_epoch: int = Field(8, description="decay epoch")
    enable_xla: bool = Field(True, description="enable XLA")
```

```bash
# è¿è¡Œä¸­ç­‰è§„æ¨¡è®­ç»ƒ
python gmantf22/train_medium.py

# ç›‘æ§
tensorboard --logdir=logs/fit_medium
```

---

### é˜¶æ®µ 3ï¸âƒ£ï¼šå®Œæ•´è®­ç»ƒ (2-4 å°æ—¶)
**ç›®æ ‡**ï¼šä½¿ç”¨å®Œæ•´é…ç½®ï¼Œä»é˜¶æ®µ2çš„æƒé‡ç»§ç»­è®­ç»ƒï¼ˆwarm startï¼‰

```bash
# æ–¹æ¡ˆA: ä»å¤´å¼€å§‹å®Œæ•´è®­ç»ƒ
python gmantf22/train.py

# æ–¹æ¡ˆB: ä»é˜¶æ®µ2çš„æƒé‡ç»§ç»­ï¼ˆæ¨èï¼‰
# åœ¨ train.py ä¸­æ·»åŠ ï¼š
# model.load_weights('./models/GMAN_medium.weights.h5')

tensorboard --logdir=logs/fit
```

---

## å¿«é€Ÿå¯¹æ¯”ä¸‰ç§é…ç½®

| é…ç½® | æ¨¡å‹å¤§å° | Batch | Epoch | è€—æ—¶ | ç”¨é€” |
|------|--------|-------|-------|------|------|
| Quick | 64ç»´ | 32 | 50 | 5-15min | å¿«é€ŸéªŒè¯ |
| Medium | 108ç»´ | 24 | 80 | 30-60min | ç²¾åº¦è°ƒæ•´ |
| Full | 320ç»´ | 12 | 100 | 2-4h | æœ€ä¼˜ç»“æœ |

---

## ğŸ’¡ å¿«é€Ÿè®­ç»ƒæŠ€å·§

### 1. æ£€æŸ¥å¿«é€Ÿæ¨¡å¼æ˜¯å¦æ”¶æ•›
```
å¦‚æœå¿«é€Ÿæ¨¡å¼ loss åœ¨ 5-10 epoch å¿«é€Ÿä¸‹é™ â†’ âœ… ç®¡é“æ­£ç¡®
å¦‚æœå¿«é€Ÿæ¨¡å¼ loss å¹³ç¼“ â†’ éœ€è¦å¢åŠ  learning_rate
å¦‚æœå¿«é€Ÿæ¨¡å¼ loss ä¸Šå‡ â†’ éœ€è¦å‡å°‘ learning_rate
```

### 2. ä»å¿«é€Ÿæ¨¡å‹å¯¼å…¥æƒé‡åˆ°å®Œæ•´æ¨¡å‹
```python
import tensorflow as tf

# å¿«é€Ÿæ¨¡å‹æƒé‡
quick_weights = './models/GMAN_quick.weights.h5'

# å®Œæ•´æ¨¡å‹æƒé‡
full_model.load_weights(quick_weights, by_name=True, skip_mismatch=True)
# è¿™æ ·ä¼šåŠ è½½æ‰€æœ‰åå­—åŒ¹é…çš„æƒé‡ï¼ˆEmbeddingã€å‰å‡ å±‚ç­‰ï¼‰
# è·³è¿‡å°ºå¯¸ä¸åŒ¹é…çš„æƒé‡ï¼ˆæ–°å¢çš„å±‚ï¼‰
```

### 3. ä½¿ç”¨ TensorBoard å¯¹æ¯”ä¸‰ä¸ªé˜¶æ®µ
```bash
# åŒæ—¶æŸ¥çœ‹æ‰€æœ‰ä¸‰ä¸ªé˜¶æ®µ
tensorboard --logdir=logs/
# ä¼šæ˜¾ç¤º fit_quick, fit_medium, fit ä¸‰ä¸ªåˆ†æ”¯
```

### 4. ç›‘æ§æŒ‡æ ‡
- **loss ä¸‹é™å¿«** â†’ å­¦ä¹ ç‡åˆé€‚ âœ…
- **loss å¹³ç¼“** â†’ å¢åŠ  learning_rate æˆ–å‡å°‘ L/K/d
- **loss æ³¢åŠ¨** â†’ å‡å°‘ learning_rate æˆ–å¢åŠ  batch_size
- **val_loss ä¸Šå‡** â†’ è¿‡æ‹Ÿåˆï¼Œå¯ç”¨æ—©åœæˆ–å¢åŠ  dropout

---

## å®é™…å·¥ä½œæµå»ºè®®

```
1. è¿è¡Œå¿«é€Ÿæ¨¡å¼ train_quick.py (5 min)
   â”œâ”€ æ£€æŸ¥ loss æ˜¯å¦ä¸‹é™
   â””â”€ æŸ¥çœ‹ TensorBoard: tensorboard --logdir=logs/fit_quick

2a. å¦‚æœå¿«é€Ÿæ¨¡å¼å¤±è´¥
   â””â”€ è°ƒæ•´ config_quick.py ä¸­çš„ learning_rate, batch_size, L
   
2b. å¦‚æœå¿«é€Ÿæ¨¡å¼æˆåŠŸ
   â””â”€ è¿è¡Œä¸­ç­‰æ¨¡å¼ train_medium.py (30 min)
   
3. å¦‚æœæ»¡è¶³ä¸­ç­‰æ¨¡å¼ç»“æœ
   â””â”€ ç»§ç»­å®Œæ•´æ¨¡å¼æˆ–å¾®è°ƒå‚æ•°
   
4. æœ€ç»ˆç”¨æœ€ä½³å‚æ•°åšå®Œæ•´è®­ç»ƒ
   â””â”€ python train.py
```

---

## å„é˜¶æ®µ Loss é¢„æœŸ

**å¿«é€Ÿæ¨¡å¼**ï¼ˆL=2, K=4, d=4ï¼‰:
```
Epoch 1:  loss â‰ˆ 50-60
Epoch 5:  loss â‰ˆ 20-30
Epoch 20: loss â‰ˆ 5-10 (å¯ç”¨)
```

**ä¸­ç­‰æ¨¡å¼**ï¼ˆL=3, K=6, d=6ï¼‰:
```
Epoch 1:  loss â‰ˆ 55-65
Epoch 10: loss â‰ˆ 15-25
Epoch 50: loss â‰ˆ 3-8 (è¾ƒå¥½)
```

**å®Œæ•´æ¨¡å¼**ï¼ˆL=5, K=8, d=8ï¼‰:
```
Epoch 1:   loss â‰ˆ 60-70
Epoch 20:  loss â‰ˆ 10-20
Epoch 100: loss â‰ˆ 1-3 (æœ€ä¼˜)
```

---

## å¸¸è§é—®é¢˜

**Q: å¿«é€Ÿæ¨¡å¼ loss ä¸ä¸‹é™ï¼Ÿ**
- A: å°è¯•å¢åŠ  learning_rate åˆ° 0.003 æˆ– 0.004

**Q: å¿«é€Ÿæ¨¡å¼è¿‡æ‹Ÿåˆæ˜æ˜¾ï¼Ÿ**
- A: å‡å°‘ L, K, dï¼Œæˆ–å¢åŠ  batch_size åˆ° 64

**Q: ä»å¿«é€Ÿæ¨¡å‹è½¬æ¢åˆ°å®Œæ•´æ¨¡å‹ï¼Ÿ**
- A: ä½¿ç”¨ `load_weights(..., by_name=True, skip_mismatch=True)`

**Q: å¦‚ä½•åªè®­ç»ƒç‰¹å®š epochï¼Ÿ**
- A: åœ¨ config ä¸­è®¾ç½® `max_epoch=20`ï¼Œé…åˆ early_stopping ä½¿ç”¨

---

## æ€»ç»“

âœ… **å¿«é€ŸéªŒè¯** (5-15 min) â†’ **ä¸­ç­‰è°ƒæ•´** (30-60 min) â†’ **å®Œæ•´è®­ç»ƒ** (2-4 h)

æ¯é˜¶æ®µéƒ½èƒ½çœ‹åˆ°å®é™…æ•ˆæœï¼Œé¿å…åœ¨å¤§æ¨¡å‹ä¸Šæµªè´¹æ—¶é—´ï¼
